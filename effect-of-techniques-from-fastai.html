<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Effect of techniques from Fast.ai - sergem personal public notebook</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="https://serge-m.github.io/effect-of-techniques-from-fastai.html">

        <meta name="author" content="SergeM" />
        <meta name="keywords" content="pytorch,deep learning,computer vision,neural networks,fast.ai,fastai,AdamW,learning rate,LRfinder,pytorch-nn-tools,resnet,one cycle" />
        <meta name="description" content="fast.ai is a brilliant library and a course by Jeremy Howard an co. They use pytorch as a base and explain deep learning from the foundations to a very decent level. In his course Jeremy Howard demonstrates a lot of interesting techniques that he finds in papers and that …" />

        <meta property="og:site_name" content="sergem personal public notebook" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Effect of techniques from Fast.ai"/>
        <meta property="og:url" content="https://serge-m.github.io/effect-of-techniques-from-fastai.html"/>
        <meta property="og:description" content="fast.ai is a brilliant library and a course by Jeremy Howard an co. They use pytorch as a base and explain deep learning from the foundations to a very decent level. In his course Jeremy Howard demonstrates a lot of interesting techniques that he finds in papers and that …"/>
        <meta property="article:published_time" content="2020-11-15" />
            <meta property="article:section" content="misc" />
            <meta property="article:tag" content="pytorch" />
            <meta property="article:tag" content="deep learning" />
            <meta property="article:tag" content="computer vision" />
            <meta property="article:tag" content="neural networks" />
            <meta property="article:tag" content="fast.ai" />
            <meta property="article:tag" content="fastai" />
            <meta property="article:tag" content="AdamW" />
            <meta property="article:tag" content="learning rate" />
            <meta property="article:tag" content="LRfinder" />
            <meta property="article:tag" content="pytorch-nn-tools" />
            <meta property="article:tag" content="resnet" />
            <meta property="article:tag" content="one cycle" />
            <meta property="article:author" content="SergeM" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="https://serge-m.github.io/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="https://serge-m.github.io/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="https://serge-m.github.io/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="https://serge-m.github.io/theme/css/style.css" type="text/css"/>

        <link href="https://serge-m.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="sergem personal public notebook ATOM Feed"/>

        <link href="https://serge-m.github.io/feeds/all.rss.xml" type="application/rss+xml" rel="alternate"
              title="sergem personal public notebook RSS Feed"/>
        <link href="https://serge-m.github.io/feeds/misc.atom.xml" type="application/atom+xml" rel="alternate"
              title="sergem personal public notebook misc ATOM Feed"/>
</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="https://serge-m.github.io/" class="navbar-brand">
sergem personal public notebook            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                        <li class="active">
                            <a href="https://serge-m.github.io/category/misc.html">Misc</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="https://serge-m.github.io/effect-of-techniques-from-fastai.html"
                       rel="bookmark"
                       title="Permalink to Effect of techniques from Fast.ai">
                        Effect of techniques from Fast.ai
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2020-11-15T10:00:00+01:00"> 2020-11-15T10:00:00, Sun</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="https://serge-m.github.io/tag/pytorch.html">pytorch</a>
        /
	<a href="https://serge-m.github.io/tag/deep-learning.html">deep learning</a>
        /
	<a href="https://serge-m.github.io/tag/computer-vision.html">computer vision</a>
        /
	<a href="https://serge-m.github.io/tag/neural-networks.html">neural networks</a>
        /
	<a href="https://serge-m.github.io/tag/fastai.html">fast.ai</a>
        /
	<a href="https://serge-m.github.io/tag/fastai.html">fastai</a>
        /
	<a href="https://serge-m.github.io/tag/adamw.html">AdamW</a>
        /
	<a href="https://serge-m.github.io/tag/learning-rate.html">learning rate</a>
        /
	<a href="https://serge-m.github.io/tag/lrfinder.html">LRfinder</a>
        /
	<a href="https://serge-m.github.io/tag/pytorch-nn-tools.html">pytorch-nn-tools</a>
        /
	<a href="https://serge-m.github.io/tag/resnet.html">resnet</a>
        /
	<a href="https://serge-m.github.io/tag/one-cycle.html">one cycle</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <p><code>fast.ai</code> is a brilliant <a href="https://github.com/fastai/fastai">library</a> and a <a href="https://course.fast.ai/">course</a> 
by Jeremy Howard an co. They use pytorch as a base and explain 
deep learning from the foundations to a very decent level. 
In his course Jeremy Howard demonstrates a lot of interesting techniques 
that he finds in papers and that do NN training faster/better/cheaper.</p>
<p>Here I want to reproduce some of the techniques in order to understand what is the effect they bring.</p>
<p>I don't want to use <a href="https://github.com/fastai/fastai">fastai library</a> here for two reasons. 
First, for better understanding of the processes it 
is better to implement them by yourself.<br>
Second, I think the library has certain disadvantages and it is better to 
stick to pytorch as close as possible. 
Fastai introduces too many layers of indirection between the user and pytorch.
It is very convenient for the beginners or for standard use cases. 
But as soon as you need something more advance you basically have 
to digg through ALL the layers of fastai to get what you want. 
I started building another <a href="https://pypi.org/project/pytorch-nn-tools/">library</a> 
that incorporates techniques from fast ai, but doesn't force the user to 
stick to the library. Hopefully. Thus I am going to use that library for my tests. </p>
<h2>Task</h2>
<p>I am going to train an image classifier 
based on Resnet18 from pytorch. 
The classifier has to distinguish between the dog breeds from
an excellent <a href="https://github.com/fastai/imagenette#imagewoof">Imagewoof</a> dataset. The dataset
is designed by Jeremy Howard again to 
for learning purposes. the dataset is small enough to 
to fast experimentation. But it also large enough and sophisticated enough
to make results and insights applicable for real datasets like Imagenet.</p>
<h2>Baseline</h2>
<p>I am going to start from SGD with 40 epochs, LR=0.1 for the first 30 epochs and 0.01 for epochs 30-40.</p>
<p>Installing dependencies:</p>
<div class="highlight"><pre><span></span><code>pip install pytorch-nn-tools<span class="o">==</span><span class="m">0</span>.3.3 <span class="nv">torch_lr_finder</span><span class="o">==</span><span class="m">0</span>.2.1
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.parallel</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">datetime</span>


<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>

<span class="kn">from</span> <span class="nn">pytorch_nn_tools.visual</span> <span class="kn">import</span> <span class="n">UnNormalize_</span><span class="p">,</span> <span class="n">imagenet_stats</span>
<span class="kn">from</span> <span class="nn">pytorch_nn_tools.train.metrics.processor</span> <span class="kn">import</span> <span class="n">mod_name_train</span><span class="p">,</span> <span class="n">mod_name_val</span><span class="p">,</span> <span class="n">Marker</span>
<span class="kn">from</span> <span class="nn">pytorch_nn_tools.train.metrics.processor</span> <span class="kn">import</span> <span class="n">MetricAggregator</span><span class="p">,</span> <span class="n">MetricLogger</span><span class="p">,</span> <span class="n">MetricType</span>
<span class="kn">from</span> <span class="nn">pytorch_nn_tools.train.progress</span> <span class="kn">import</span> <span class="n">ProgressTracker</span>
<span class="kn">from</span> <span class="nn">pytorch_nn_tools.convert</span> <span class="kn">import</span> <span class="n">map_dict</span>
<span class="kn">from</span> <span class="nn">pytorch_nn_tools.train.metrics.history_condition</span> <span class="kn">import</span> <span class="n">HistoryCondition</span>
<span class="kn">from</span> <span class="nn">pytorch_nn_tools.train.checkpoint</span> <span class="kn">import</span> <span class="n">CheckpointSaver</span>
</code></pre></div>

<p>Functions for generating datasets</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">_train_dataset</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
        <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
        <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="n">train_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span>
        <span class="n">train_dir</span><span class="p">,</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">normalize</span><span class="p">,</span>
        <span class="p">]))</span>
    <span class="k">return</span> <span class="n">train_dataset</span>


<span class="k">def</span> <span class="nf">_val_dataset</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
        <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
        <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">val_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">val_dir</span><span class="p">,</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">normalize</span><span class="p">,</span> <span class="p">]))</span>
    <span class="k">return</span> <span class="n">dataset</span>
</code></pre></div>

<p>Settings and data loaders:</p>
<div class="highlight"><pre><span></span><code><span class="n">batch_size_train</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">batch_size_val</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>


<span class="n">data_path</span> <span class="o">=</span> <span class="s2">&quot;data/imagewoof2-320/&quot;</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">_train_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size_train</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">val_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">_val_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size_val</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>

<p>Accuracy function from pytorch-lightning:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)):</span>
    <span class="sd">&quot;&quot;&quot;Computes the accuracy over the k top predictions for the specified values of k&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">maxk</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">topk</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">maxk</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>

        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">topk</span><span class="p">:</span>
            <span class="n">correct_k</span> <span class="o">=</span> <span class="n">correct</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correct_k</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">res</span>
</code></pre></div>

<p>Some helper functions:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>

<span class="k">class</span> <span class="nc">PBars</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_main</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_second</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">it</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_main</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_main</span>

    <span class="k">def</span> <span class="nf">secondary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">it</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_main</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot instantiate secondary progress bar. The main progress bar is not set.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_second</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_main</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_second</span>

    <span class="k">def</span> <span class="nf">main_comment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">comment</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_main</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="n">comment</span>

<span class="k">def</span> <span class="nf">now_as_str</span><span class="p">():</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">now</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M</span><span class="si">%s</span><span class="s2">_</span><span class="si">%f</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DummyLogger</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">debug</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>

<p>TrainerIO is responsible for logging and checkpointing.
That is the class that does IO on behalf of a trainer.
It can 1) instantiate metric logger. 2) load last checkpoint and 3) save checkpoints</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">TrainerIO</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">experiment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">checkpoint_condition</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">MetricType</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">experiment_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path_experiment</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path_checkpoints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">path_experiment</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;checkpoints&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_saver</span> <span class="o">=</span> <span class="n">CheckpointSaver</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path_checkpoints</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="n">DummyLogger</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_condition</span> <span class="o">=</span> <span class="n">checkpoint_condition</span>

    <span class="k">def</span> <span class="nf">create_metric_logger</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">path_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">path_experiment</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">now_as_str</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">metric_logger</span> <span class="o">=</span> <span class="n">MetricLogger</span><span class="p">(</span><span class="n">path_logs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">metric_logger</span>

    <span class="k">def</span> <span class="nf">load_last</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">end_epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_saver</span><span class="o">.</span><span class="n">find_last</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">end_epoch</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">last</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;found pretrained results for epoch </span><span class="si">{</span><span class="n">last</span><span class="si">}</span><span class="s2">. Loading...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_saver</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">last</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">last</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">start_epoch</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">MetricType</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_condition</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</code></pre></div>

<p>Now goes the trainer. In fastai and pytorch-lightning frameworks 
the trainers are implemented inside the library. The user has to use callbacks of inheritance 
in order to patch the standard trainer loop.
That means the trainer has to be overly generic. For each case the user has to know how 
which callback to use and how the result of that callback influences the training logic.
That look like a leaking abstraction to me. In that case the library doesn't really abstract anything. 
The user has to know all the internals in order to do even moderately difficult things with it.</p>
<p>I have a hypothesis that it is possible to inverse that dependency. I want the user to write a training
loop on it's own. I want my library to provide helper functions for that in order to make it super easy.</p>
<p>The biggest part of the training loop is IO: checkpointing, logging, data loading. There is 
very little amount of logic. I hypothesize that it may has no sense to extract it to a library. Let
the user write it, but make it simple.</p>
<p>It's not a finalized version btw. Some of the parts may be included into <code>pytorch-nn-tools</code> 
in the future. </p>
<p>The trainer has main function <code>fit(...)</code> that calls <code>train_epoch(...)</code> and <code>validate_epoch(...)</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">trainer_io</span><span class="p">:</span> <span class="n">TrainerIO</span><span class="p">,</span>
                <span class="n">continue_training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">continue_training</span> <span class="o">=</span> <span class="n">continue_training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer_io</span> <span class="o">=</span> <span class="n">trainer_io</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pbars</span> <span class="o">=</span> <span class="n">PBars</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">start_epoch</span><span class="p">,</span> <span class="n">end_epoch</span><span class="p">):</span>
        <span class="n">metric_logger</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer_io</span><span class="o">.</span><span class="n">create_metric_logger</span><span class="p">()</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">continue_training</span><span class="p">:</span>
            <span class="n">start_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer_io</span><span class="o">.</span><span class="n">load_last</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">end_epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>

        <span class="n">progr_train</span> <span class="o">=</span> <span class="n">ProgressTracker</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pbars</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">end_epoch</span><span class="p">)):</span>
            <span class="n">metric_aggregator</span> <span class="o">=</span> <span class="n">MetricAggregator</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span>
                <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">progr_train</span><span class="p">,</span>
                <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>  
                <span class="n">metric_proc</span><span class="o">=</span><span class="n">mod_name_train</span><span class="o">+</span><span class="n">metric_aggregator</span><span class="o">+</span><span class="n">metric_logger</span><span class="p">,</span>
                <span class="n">pbars</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pbars</span><span class="p">,</span>
                <span class="n">report_step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">tb_writer</span><span class="o">=</span><span class="n">metric_logger</span><span class="o">.</span><span class="n">writer</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">validate_epoch</span><span class="p">(</span>
                <span class="n">val_dataloader</span><span class="p">,</span>
                <span class="n">model</span><span class="p">,</span>  
                <span class="n">metric_proc</span><span class="o">=</span><span class="n">mod_name_val</span><span class="o">+</span><span class="n">metric_aggregator</span><span class="o">+</span><span class="n">metric_logger</span><span class="p">,</span>
                <span class="n">pbars</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pbars</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">aggregated</span> <span class="o">=</span> <span class="n">map_dict</span><span class="p">(</span><span class="n">metric_aggregator</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(),</span> <span class="n">key_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">key</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;avg.</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">metric_logger</span><span class="p">({</span>
                <span class="o">**</span><span class="n">aggregated</span><span class="p">,</span> 
                <span class="o">**</span><span class="p">{</span><span class="sa">f</span><span class="s2">&quot;lr_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">lr</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">lr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">())},</span>
                <span class="n">Marker</span><span class="o">.</span><span class="n">EPOCH</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="p">})</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pbars</span><span class="o">.</span><span class="n">main_comment</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">aggregated</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">trainer_io</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">aggregated</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># for epoch-based scheduler</span>

        <span class="n">metric_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">progr</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric_proc</span><span class="p">,</span> <span class="n">pbars</span><span class="p">,</span> <span class="n">report_step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                   <span class="n">tb_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">progr</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">pbars</span><span class="o">.</span><span class="n">secondary</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">images</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">progr</span><span class="o">.</span><span class="n">cnt_total_iter</span> <span class="o">%</span> <span class="n">report_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">acc1</span><span class="p">,</span> <span class="n">acc5</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

                <span class="n">metric_proc</span><span class="p">({</span>
                    <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc1&#39;</span><span class="p">:</span> <span class="n">acc1</span><span class="p">,</span> <span class="s1">&#39;acc5&#39;</span><span class="p">:</span> <span class="n">acc5</span><span class="p">,</span> <span class="n">Marker</span><span class="o">.</span><span class="n">ITERATION</span><span class="p">:</span> <span class="n">progr</span><span class="o">.</span><span class="n">cnt_total_iter</span><span class="p">,</span>
                    <span class="o">**</span><span class="p">{</span><span class="sa">f</span><span class="s2">&quot;lr_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">lr</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">lr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">())},</span>
                <span class="p">})</span>

<span class="c1">#             scheduler.step()  # for batch based scheduler</span>

    <span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metric_proc</span><span class="p">,</span> <span class="n">pbars</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pbars</span><span class="o">.</span><span class="n">secondary</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                <span class="n">acc1</span><span class="p">,</span> <span class="n">acc5</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

                <span class="n">metric_proc</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">acc1</span><span class="o">=</span><span class="n">acc1</span><span class="p">,</span> <span class="n">acc5</span><span class="o">=</span><span class="n">acc5</span><span class="p">))</span>
</code></pre></div>

<p>Finally the main part</p>
<div class="highlight"><pre><span></span><code><span class="n">recommended_lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">40</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>        

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span>
    <span class="p">{</span>
        <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;main_model&#39;</span><span class="p">,</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">])</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="k">lambda</span> <span class="n">epoch</span><span class="p">:</span> <span class="mf">0.1</span> <span class="o">**</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">//</span> <span class="mi">30</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">trainer_io</span> <span class="o">=</span> <span class="n">TrainerIO</span><span class="p">(</span>
    <span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./logs/&quot;</span><span class="p">,</span> <span class="n">experiment_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;experiment1_onecycle_lr</span><span class="si">{</span><span class="n">recommended_lr</span><span class="si">}</span><span class="s2">_adamw&quot;</span><span class="p">,</span> 
    <span class="n">checkpoint_condition</span><span class="o">=</span><span class="n">HistoryCondition</span><span class="p">(</span>
        <span class="s1">&#39;avg.val.acc1&#39;</span><span class="p">,</span> 
        <span class="k">lambda</span> <span class="n">hist</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">hist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">hist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">max</span><span class="p">(</span><span class="n">hist</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">trainer_io</span><span class="o">=</span><span class="n">trainer_io</span><span class="p">,</span> <span class="n">continue_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>
    <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_epoch</span><span class="o">=</span><span class="n">num_epochs</span>
<span class="p">)</span>
</code></pre></div>

<p>In order to run the trainer the user has to define TrainerIO, model, scheduler and optimizer. 
All those parts are interconnected and essential for the process.</p>
<p>We achieve accuracy for top 1 about 69% and for top 5 about 96 %. That is in line with the
values that other people get for that dataset: <a href="https://github.com/fastai/imagenette#imagewoof-leaderboard">Imagewoof Leaderboard</a></p>
<p><img alt="" src="media/2020-11-14/lr_base_avg.val.acc1.svg">
<em>top1 accuracy</em></p>
<p><img alt="" src="media/2020-11-14/lr_base_avg.val.acc5.svg">
<em>top5 accuracy</em></p>
<h2>LR Finder</h2>
<p>One of the greatest things I found in fastai is learning rate finder. It is a technique that
helps to set up the initial (base) learning rate for the models.  </p>
<p>The idea is to do the iteration of the training for gradually increasing learning rate. 
The learning rate value where we see the fastest descent of the loss is a good chioce.</p>
<p>I am not going to write that LR finder myself and 
I use the existing module <a href="https://pypi.org/project/torch-lr-finder/">pytorch-lr-finder</a>, 
<a href="https://github.com/davidtvs/pytorch-lr-finder">github</a>.
That module works with standard pytorch concepts. 
If I would like to use the LRFinder from fast ai or pytorch lightning, I would be forced to 
use their trainers, optimizers etc.</p>
<p>Let's create a new model and optimizer. We start with a very low learning rate: 1e-8. The lr_finder will do 50 iterations 
up until lr=10.:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>        

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">([</span>
    <span class="p">{</span>
        <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;main_model&#39;</span><span class="p">,</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">])</span>

<span class="kn">from</span> <span class="nn">torch_lr_finder</span> <span class="kn">import</span> <span class="n">LRFinder</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">lr_finder</span> <span class="o">=</span> <span class="n">LRFinder</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">lr_finder</span><span class="o">.</span><span class="n">range_test</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">val_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end_lr</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">step_mode</span><span class="o">=</span><span class="s2">&quot;exp&quot;</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">recommended_lr</span> <span class="o">=</span> <span class="n">lr_finder</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log_lr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">lr_finder</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</code></pre></div>

<p><img alt="" src="media/2020-11-14/lr_finder.png"></p>
<p>My recommended LR is about 0.02. I can launch with the same optimizer, lr schedule, but with the new base LR:</p>
<div class="highlight"><pre><span></span><code><span class="n">recommended_lr</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>        

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span>
    <span class="p">{</span>
        <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;main_model&#39;</span><span class="p">,</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">recommended_lr</span><span class="p">,</span>
        <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">])</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">max_lr</span><span class="o">=</span><span class="n">recommended_lr</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

<p>Here also we have to patch our trainer. Scheduler step now happens for each training batch, not per epoch.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="c1"># .....</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">start_epoch</span><span class="p">,</span> <span class="n">end_epoch</span><span class="p">):</span>
        <span class="c1"># ....</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pbars</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">end_epoch</span><span class="p">)):</span>
            <span class="c1"># .....</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer_io</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">aggregated</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="c1"># not needed any more</span>
            <span class="c1"># scheduler.step() </span>

        <span class="n">metric_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">progr</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric_proc</span><span class="p">,</span> <span class="n">pbars</span><span class="p">,</span> <span class="n">report_step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                   <span class="n">tb_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">progr</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">pbars</span><span class="o">.</span><span class="n">secondary</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))):</span>
            <span class="c1"># ...</span>

            <span class="c1"># now we do scheduler step for every batch</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> 

    <span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metric_proc</span><span class="p">,</span> <span class="n">pbars</span><span class="p">):</span>
        <span class="c1"># stays the same</span>
        <span class="c1"># ...</span>
</code></pre></div>

<p>Let's run:</p>
<div class="highlight"><pre><span></span><code><span class="n">trainer_io</span> <span class="o">=</span> <span class="n">TrainerIO</span><span class="p">(</span>
    <span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./logs/&quot;</span><span class="p">,</span> <span class="n">experiment_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;experiment_base_lr</span><span class="si">{</span><span class="n">recommended_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> 
    <span class="n">checkpoint_condition</span><span class="o">=</span><span class="n">HistoryCondition</span><span class="p">(</span>
        <span class="s1">&#39;avg.val.acc1&#39;</span><span class="p">,</span> 
        <span class="k">lambda</span> <span class="n">hist</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">hist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">hist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">max</span><span class="p">(</span><span class="n">hist</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">trainer_io</span><span class="o">=</span><span class="n">trainer_io</span><span class="p">,</span> <span class="n">continue_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>
    <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_epoch</span><span class="o">=</span><span class="n">num_epochs</span>
<span class="p">)</span>
</code></pre></div>

<p><img alt="training loss after lr finder" src="media/2020-11-14/lr_base_vs_finder_avg.train.loss.svg"> 
<em>train loss. lr=0.1 vs lr=0.02 found by LRFinder</em></p>
<p>Top 1 Accuracy improved significantly from 0.69 to 0.78!</p>
<p><img alt="top 1 accuracy after lr finder" src="media/2020-11-14/lr_base_vs_finder_avg.val.acc1.svg"> 
<em>top 1 accuracy on validation. lr=0.1 vs lr=0.02 found by LRFinder</em></p>
<h2>One Cycle learning rate</h2>
<p>Another technique is to have a special LR schedule. We start small, ramp it up quickly to the maximum and then 
gradually decrease.</p>
<p>Here is how the LR graphs look like:</p>
<p><img alt="learning rate schedules" src="media/2020-11-14/lr_one_cycle.svg">
<em>learning rate schedules. Gray line is a "one cycle"</em></p>
<p>We don't get accuracy increase here. But we don't need to hand craft the learning rate schedule any more. 
That is positive.</p>
<p>Hopefully one cycle brings some numerical stability. </p>
<p><img alt="accuracy top 1 for one cycle" src="media/2020-11-14/one_cycle_avg.val.acc1.svg">
<em>Accuracy top 1 for one cycle. Gray line is a "one cycle"</em></p>
<h2>AdamW</h2>
<p>Instead of SGD let's use Adam optimizer. More specifically AdamW version of it. It was also advertised 
in fastai as a good practice.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>        

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">([</span>
    <span class="p">{</span>
        <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;main_model&#39;</span><span class="p">,</span>
        <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">recommended_lr</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">])</span>


<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">max_lr</span><span class="o">=</span><span class="n">recommended_lr</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">trainer_io</span> <span class="o">=</span> <span class="n">TrainerIO</span><span class="p">(</span>
    <span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./logs/&quot;</span><span class="p">,</span> <span class="n">experiment_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;experiment1_onecycle_lr</span><span class="si">{</span><span class="n">recommended_lr</span><span class="si">}</span><span class="s2">_adamw&quot;</span><span class="p">,</span> 
    <span class="n">checkpoint_condition</span><span class="o">=</span><span class="n">HistoryCondition</span><span class="p">(</span>
        <span class="s1">&#39;avg.val.acc1&#39;</span><span class="p">,</span> 
        <span class="k">lambda</span> <span class="n">hist</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">hist</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">hist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">max</span><span class="p">(</span><span class="n">hist</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">trainer_io</span><span class="o">=</span><span class="n">trainer_io</span><span class="p">,</span> <span class="n">continue_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>
    <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_epoch</span><span class="o">=</span><span class="n">num_epochs</span>
<span class="p">)</span>
</code></pre></div>

<p>That helps a lot. We go from 79.5% to 82.6% of accuracy: </p>
<p><img alt="accuracy top 1 for one cycle" src="media/2020-11-14/adamw_avg.val.acc1.svg">
<em>Accuracy top 1 for AdamW. Dark red line is a AdamW</em></p>
<p><img alt="train loss for one cycle" src="media/2020-11-14/adamw_avg.train.loss.svg">
<em>Train loss for AdamW. Dark red line is a AdamW</em></p>
<h2>Conclusion</h2>
<p>We used a fraction of tricks from fastai to improve the performance of our training. They all seem to be useful.
Only OneCycle scheduler didn't bring an evident benefits in the accuracy. However it brings some simplicity 
for developer. <br>
The numbers are still pretty far from the values on the leaderboard, but we didn't use all the tricks of course. </p>
<p>Also here we verified the viability of pytorch-nn-tools library.</p>
            </div>
            <!-- /.entry-content -->
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'serge-m-github-io'; // required: replace example with your forum shortname

            var disqus_config = function () {
                this.language = "en";

                        this.page.identifier = '2020-11-15-effect-of-techniques-from-fastai';
                        this.page.url = 'https://serge-m.github.io/effect-of-techniques-from-fastai.html';
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Recent Posts -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Recent Posts</span></h4>
  <ul class="list-group" id="recentposts">
    <li class="list-group-item"><a href="https://serge-m.github.io/effect-of-techniques-from-fastai.html">Effect of techniques from Fast.ai</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/point-cloud-processing.html">Point cloud processing</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/python-multiprocessing.html">Python - Multiprocessing</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/self-supervised-depth-and-ego-motion.html">Self-supervised depth and ego motion estimation</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/which-backbone-to-choose.html">Which pretrained backbone to choose</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/parameters-parsing-for-python-applications.html">Parameters parsing for python applications</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/git-cheat-sheet.html">Git cheat sheet</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/image-and-video-processing-recipes.html">Image and video processing recipes</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/cpp-and-cmake.html">C++ and CMake</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/system-monitoring.html">System monitoring</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/blinking-multiple-leds-with-arduino-atmega328p-and-pca9685.html">Blinking multiple LEDs with Arduino (ATMega328p) and PCA9685</a></li>
    <li class="list-group-item"><a href="https://serge-m.github.io/capture-pwm-signal-using-arduino.html">Capture PWM signal using Arduino</a></li>
  </ul>
</li>
<!-- End Sidebar/Recent Posts -->

<!-- Sidebar/Categories -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Categories</span></h4>
  <ul class="list-group" id="categories">
    <li class="list-group-item">
      <a href="https://serge-m.github.io/category/misc.html"><i class="fa fa-folder-open fa-lg"></i>misc</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Categories -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="https://serge-m.github.io/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/adamw.html">AdamW</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/after-effects-aae.html">after effects (aae)</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/arduino.html">arduino</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/argparse.html">argparse</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/avconv.html">avconv</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/best-practices.html">best practices</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/books.html">books</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="https://serge-m.github.io/tag/c.html">c++</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/camera.html">camera</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/cheatsheet.html">cheatsheet</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/click.html">click</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/cmake.html">cmake</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/cnn.html">CNN</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/command-line.html">command line</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/computer-vision.html">computer vision</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/configuration.html">configuration</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/console.html">console</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/cpp.html">cpp</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/deep-learning.html">deep learning</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/depth.html">depth</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/dll.html">dll</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/dnn.html">DNN</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/docker.html">docker</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/draft.html">draft</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/ego-motion.html">ego motion.</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/errors.html">errors</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/fastai.html">fast.ai</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/ffmpeg.html">ffmpeg</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/flask.html">flask</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/git.html">git</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/hardware.html">hardware</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/html.html">html</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/image.html">image</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/image-processing.html">image processing</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/images.html">images</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/interview.html">interview</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/ipython.html">ipython</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/java.html">java</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/javascript.html">javascript</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/jupyter.html">jupyter</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/latex.html">latex</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/learning-rate.html">learning rate</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/libraries.html">libraries</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/links.html">links</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="https://serge-m.github.io/tag/linux.html">linux</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/linux-for-dummies.html">Linux for dummies</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/linux-mint.html">linux mint</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/lrfinder.html">LRfinder</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/machine-learning.html">machine learning</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/management.html">management</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/matlab.html">matlab</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/memory.html">memory</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/multiprocessing.html">multiprocessing</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/network.html">network</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/neural-networks.html">neural networks</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/nuke.html">nuke</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/numpy.html">numpy</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/one-cycle.html">one cycle</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/opencv.html">opencv</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/openvpn.html">openvpn</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/optical-flow.html">optical flow</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/pca9685.html">pca9685</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/pcl.html">pcl</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/pelican.html">pelican</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/pi.html">pi</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/ply.html">ply</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/pm.html">pm</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/point-cloud.html">point cloud</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/pwm.html">pwm</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/pypy.html">pypy</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/pytest.html">pytest</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="https://serge-m.github.io/tag/python.html">python</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/pytorch.html">pytorch</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/pytorch-nn-tools.html">pytorch-nn-tools</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/raspberry.html">raspberry</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/raspberry-pi.html">raspberry pi</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://serge-m.github.io/tag/resnet.html">resnet</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/rest.html">REST</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/robocar.html">robocar</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/robotics.html">robotics</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/ros.html">ros</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/russian.html">russian</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/server.html">server</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/software.html">software</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/spark.html">spark</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/sql.html">sql</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/ssh.html">ssh</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/tensorflow.html">tensorflow</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/testing.html">testing</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/tools.html">tools</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/torch.html">torch</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/travisci.html">travisci</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/ubuntu.html">ubuntu</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="https://serge-m.github.io/tag/useful.html">useful</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://serge-m.github.io/tag/video.html">video</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/video-processing.html">video processing</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/vim.html">vim</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/visual-studio.html">visual studio</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/windows.html">windows</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="https://serge-m.github.io/tag/youtube.html">youtube</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="/pages/collection-of-interesting-databases.html" target="_blank">Databases</a>
    </li>
    <li class="list-group-item">
      <a href="/pages/posts-by-year.html" target="_blank">Posts by year</a>
    </li>
    <li class="list-group-item">
      <a href="/books.html" target="_blank">Books</a>
    </li>
    <li class="list-group-item">
      <a href="/tag/useful.html" target="_blank">Useful</a>
    </li>
    <li class="list-group-item">
      <a href="/bjontegaard-metric-matlab-script.html" target="_blank">Bjontegaard metric in Matlab</a>
    </li>
    <li class="list-group-item">
      <a href="feeds/all.rss.xml" target="_blank">RSS</a>
    </li>
    <li class="list-group-item">
      <a href="feeds/all.atom.xml" target="_blank">Atom</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2020 sergem
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="https://serge-m.github.io/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="https://serge-m.github.io/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="https://serge-m.github.io/theme/js/respond.min.js"></script>


    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'serge-m-github-io'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->
    <!-- Google Analytics -->
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-40853494-2']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- End Google Analytics Code -->


</body>
</html>