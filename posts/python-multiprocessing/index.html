<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Python - Multiprocessing | sergem's personal public notebook</title>
<meta name=keywords content="python,multiprocessing,useful,libraries,multiprocessing">
<meta name=description content="Libraries   Standard multiprocessing
  Pebble - pretty close to the standard one, but with a bit nicer interface
  Dask - well maintained and (almost) drop-in replacement of numpy and pandas:
  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Arrays implement the Numpy API import dask.array as da x = da.random.random(size=(10000, 10000), chunks=(1000, 1000)) x + x.">
<meta name=author content="SergeM">
<link rel=canonical href=https://serge-m.github.io/posts/python-multiprocessing/>
<link href=/assets/css/stylesheet.min.6d98a2276d0cb41ef459267b3ff3ef02df70a8f16b70bbc52b20568702bc90cf.css integrity="sha256-bZiiJ20MtB70WSZ7P/PvAt9wqPFrcLvFKyBWhwK8kM8=" rel="preload stylesheet" as=style>
<link rel=icon href=https://serge-m.github.io/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://serge-m.github.io/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://serge-m.github.io/favicon-32x32.png>
<link rel=apple-touch-icon href=https://serge-m.github.io/apple-touch-icon.png>
<link rel=mask-icon href=https://serge-m.github.io/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.2">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-40853494-2','auto'),ga('send','pageview'))</script><meta property="og:title" content="Python - Multiprocessing">
<meta property="og:description" content="Libraries   Standard multiprocessing
  Pebble - pretty close to the standard one, but with a bit nicer interface
  Dask - well maintained and (almost) drop-in replacement of numpy and pandas:
  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Arrays implement the Numpy API import dask.array as da x = da.random.random(size=(10000, 10000), chunks=(1000, 1000)) x + x.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://serge-m.github.io/posts/python-multiprocessing/"><meta property="og:image" content="https://serge-m.github.io/papermod-cover.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2020-10-01T20:00:00+00:00">
<meta property="article:modified_time" content="2020-10-01T20:00:00+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://serge-m.github.io/papermod-cover.png">
<meta name=twitter:title content="Python - Multiprocessing">
<meta name=twitter:description content="Libraries   Standard multiprocessing
  Pebble - pretty close to the standard one, but with a bit nicer interface
  Dask - well maintained and (almost) drop-in replacement of numpy and pandas:
  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Arrays implement the Numpy API import dask.array as da x = da.random.random(size=(10000, 10000), chunks=(1000, 1000)) x + x.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://serge-m.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Python - Multiprocessing","item":"https://serge-m.github.io/posts/python-multiprocessing/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Python - Multiprocessing","name":"Python - Multiprocessing","description":"Libraries   Standard multiprocessing\n  Pebble - pretty close to the standard one, but with a bit nicer interface\n  Dask - well maintained and (almost) drop-in replacement of numpy and pandas:\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Arrays implement the Numpy API import dask.array as da x = da.random.random(size=(10000, 10000), chunks=(1000, 1000)) x + x.","keywords":["python","multiprocessing","useful","libraries","multiprocessing"],"articleBody":"Libraries   Standard multiprocessing\n  Pebble - pretty close to the standard one, but with a bit nicer interface\n  Dask - well maintained and (almost) drop-in replacement of numpy and pandas:\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Arrays implement the Numpy API import dask.array as da x = da.random.random(size=(10000, 10000), chunks=(1000, 1000)) x + x.T - x.mean(axis=0) # Dataframes implement the Pandas API import dask.dataframe as dd df = dd.read_csv('s3://.../2018-*-*.csv') df.groupby(df.account_id).balance.sum() # Dask-ML implements the Scikit-Learn API from dask_ml.linear_model \\ import LogisticRegression lr = LogisticRegression() lr.fit(train, test)     mptools - seems like an abandoned project. The autor had a nice article though: Things I Wish They Told Me About Multiprocessing in Python\n  Ray\nRelated article: 10x Faster Parallel Python Without Python Multiprocessing\n   Progress bar for parallel tasks Often one need to run some slow function in parallel in order to speed up the computation. In user facing apps it’s important to visualize the progress. One can use multiprocessing.Pool and tqdm for it.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import multiprocessing import numpy as np import tqdm def slow_operation(a): \"\"\" Slow operation, return value is not needed in main. For example the function opens a file, processes it and dumps the results to a new location. \"\"\" z = np.random.random([1000, 1000]) for i in range(50): z = z * (z - 0.5) return z   One cannot apply tqdm to the Pool.map because the whole processing happens before the tqdm can iterate the result.\nHowever it’s possible to use Pool.imap or Pool.imap_unordered if the order is not important.\n1 2 3 4 5  def parallel_with_imap_unordered(): with multiprocessing.Pool(6) as pool: for _ in tqdm.tqdm(pool.imap_unordered(slow_operation, range(100)), total=100): pass   It’s nice that we don’t need to do pool.join() here because imap* waits for all the tasks to complete.\nDon’t forget to set chunk size:\n For very long iterables using a large value for chunksize can make the job complete much faster than using the default value of 1.\n Alternatively we can use callbacks to update a global progress bar in a main process:\n1 2 3 4 5 6 7 8 9 10 11  def parallel_with_callback(): pbar = tqdm.tqdm(total=100) def update(*a): pbar.update() pool = multiprocessing.Pool(6) for i in range(pbar.total): pool.apply_async(slow_operation, args=(i,), callback=update) pool.close() pool.join()   That method requires pool.join to wait for all the processes to finish.\nUsing Pipes for parallel stateful processes Let’s consider the following task. We have to implement a controller. The controller defines a processing graph with 4 interconnected stages:\n  detector\n  size_estimator (depends on detector)\n  classifier (depends on detector)\n  aggregator (depends on size_estimator and classifier)\n  This could be a model for some computer vision pipeline and controller processes frames coming from a camera.\nSequential version of the controller could look like this\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Controller: def __init__(self): self.detector = Detector() self.size_estimator = Processor(fn=_compute_size) self.classifier = Processor(fn=_obj_to_class) self.aggregator = Aggregator() self.stats = [] def __call__(self, frame): objects = self.detector(frame) sizes = self.size_estimator(objects) classes = self.classifier(objects) stat = self.aggregator(sizes, classes) self.stats.append(stat) def finish(self): pass   Usage of the controller:\n1 2 3 4 5 6 7 8 9 10  def execute_test(controller): num_frames = 10 t = time.time() for i in range(num_frames): frame = np.empty((100, 100), dtype='uint8') controller(frame) controller.finish() t = time.time() - t print(f\"FPS: {num_frames / t}\") return t   As I have mentioned above two stages - size estimation and classification - can be executed in parallel. A standard solution for that could be multiprocessing.Pool with a function like map or imap. That works if our processing stages are stateless and the initialization is cheap It is not always the case.\nIf classifier requires a costly initialization, e.g. loading a big neural network into memory, it would be nice to have it initialized only once. We can do it in a separate process. If we were using a programming language other than Python, we could use threads for it. But in python we have GIL.\nController has to send data to another process and receive the results. Communication between parallel processes is a dangerous thing. Let’s try to use multiprocessing.Pipe for that.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  class ParallelPipeController: def __init__(self, size_estimator_factory=lambda: Processor(fn=_compute_size)): self.pipe_size_estimator, pipe_size_worker = Pipe() self.detector = Detector() self.size_estimator = Process( target=pipe_worker, args=(pipe_size_worker, size_estimator_factory), daemon=True ) self.classifier = Processor(fn=_obj_to_class) self.aggregator = Aggregator() self.stats = [] self.size_estimator.start() def __call__(self, frame): objects = self.detector(frame) self.pipe_size_estimator.send(objects) classes = self.classifier(objects) try: sizes = self.pipe_size_estimator.recv() except EOFError as e: raise RuntimeError(\"Unable to get data from process. Probably exception occurred\") from e stat = self.aggregator(sizes, classes) self.stats.append(stat) def finish(self): self.pipe_size_estimator.send(None) self.size_estimator.join()   pipe_worker would look like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def pipe_worker(pipe, factory: Callable): try: print(\"worker started\") processor = factory() while True: msg = pipe.recv() if msg is None: break result = processor(msg) pipe.send(result) print(\"worker exited correctly\") except Exception: print(\"An exception occurred. We notify the main process by closing our end of the pipe.\" \"It would be nicer to send some info to the main process.\") pipe.close()   Comparing those two controllers:\n1 2 3 4  print(\"sequential\") execute_test(Controller()) print(\"parallel\") execute_test(ParallelPipeController())   Sample output:\nsequential FPS: 1.7753397948365568 parallel worker started worker exited correctly FPS: 2.820896038347416  Full code is here.\nThere are some alternative workarounds to deal with initialization in standard multiprocessing. They usually require some global variables. See for example:\n  Stack overflow how to use initializer to set up my multiprocess pool?\n  Multiprocessing.Pool - Pass Data to Workers w/o Globals: A Proposal\n  Processing KeyboardInterrupt in workers Apparently there are some issue with KeyboardInterrupt and multiprocessing:\n when workers are idle, Python’s KeyboardInterrupt is not handled correctly by the multiprocessing module, which results in not only a lot of stacktraces spewed to the console, but also means the parent process will hang indefinitely.\n Python: Using KeyboardInterrupt with a Multiprocessing Pool, 2011.\n","wordCount":"1007","inLanguage":"en","datePublished":"2020-10-01T20:00:00Z","dateModified":"2020-10-01T20:00:00Z","author":{"@type":"Person","name":"SergeM"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://serge-m.github.io/posts/python-multiprocessing/"},"publisher":{"@type":"Organization","name":"sergem's personal public notebook","logo":{"@type":"ImageObject","url":"https://serge-m.github.io/favicon.ico"}}}</script>
</head>
<body id=top>
<script>window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<noscript>
<style type=text/css>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://serge-m.github.io/ accesskey=h title="Home (Alt + H)">Home</a>
<span class=logo-switches>
</span>
</div>
<ul id=menu onscroll=menu_on_scroll()>
<li>
<a href=https://serge-m.github.io/archives title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://serge-m.github.io/categories/ title=Categories>
<span>Categories</span>
</a>
</li>
<li>
<a href=https://serge-m.github.io/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
<li>
<a href=https://serge-m.github.io/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://serge-m.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://serge-m.github.io/posts/>Posts</a></div>
<h1 class=post-title>
Python - Multiprocessing
</h1>
<div class=post-meta>October 1, 2020&nbsp;·&nbsp;SergeM
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<div class=details>Table of Contents</div>
</summary>
<div class=inner><ul><ul>
<li>
<a href=#libraries aria-label=Libraries>Libraries</a></li>
<li>
<a href=#progress-bar-for-parallel-tasks aria-label="Progress bar for parallel tasks">Progress bar for parallel tasks</a></li>
<li>
<a href=#using-pipes-for-parallel-stateful-processes aria-label="Using Pipes for parallel stateful processes">Using Pipes for parallel stateful processes</a></li></ul>
<li>
<a href=#processing-keyboardinterrupt-in-workers aria-label="Processing KeyboardInterrupt in workers">Processing KeyboardInterrupt in workers</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><h2 id=libraries>Libraries<a hidden class=anchor aria-hidden=true href=#libraries>#</a></h2>
<ul>
<li>
<p>Standard <a href=https://docs.python.org/3/library/multiprocessing.html>multiprocessing</a></p>
</li>
<li>
<p><a href=https://pypi.org/project/Pebble/>Pebble</a>
- pretty close to the standard one, but with a bit nicer interface</p>
</li>
<li>
<p><a href=https://dask.org/>Dask</a>
- well maintained and (almost) drop-in replacement of numpy and pandas:</p>
</li>
</ul>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=c1># Arrays implement the Numpy API</span>
<span class=kn>import</span> <span class=nn>dask.array</span> <span class=k>as</span> <span class=nn>da</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>da</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>10000</span><span class=p>,</span> <span class=mi>10000</span><span class=p>),</span>
                     <span class=n>chunks</span><span class=o>=</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>1000</span><span class=p>))</span>
<span class=n>x</span> <span class=o>+</span> <span class=n>x</span><span class=o>.</span><span class=n>T</span> <span class=o>-</span> <span class=n>x</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>

<span class=c1># Dataframes implement the Pandas API</span>
<span class=kn>import</span> <span class=nn>dask.dataframe</span> <span class=k>as</span> <span class=nn>dd</span>
<span class=n>df</span> <span class=o>=</span> <span class=n>dd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;s3://.../2018-*-*.csv&#39;</span><span class=p>)</span>
<span class=n>df</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>account_id</span><span class=p>)</span><span class=o>.</span><span class=n>balance</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

<span class=c1># Dask-ML implements the Scikit-Learn API</span>
<span class=kn>from</span> <span class=nn>dask_ml.linear_model</span> \
  <span class=kn>import</span> <span class=nn>LogisticRegression</span>
<span class=n>lr</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>()</span>
<span class=n>lr</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><a href=https://github.com/PamelaM/mptools>mptools</a> - seems like an abandoned project.
The autor had a nice article though:
<a href=https://www.cloudcity.io/blog/2019/02/27/things-i-wish-they-told-me-about-multiprocessing-in-python/>Things I Wish They Told Me About Multiprocessing in Python</a></p>
</li>
<li>
<p><a href=https://github.com/ray-project/ray>Ray</a></p>
<p>Related article:
<a href=https://towardsdatascience.com/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1>10x Faster Parallel Python Without Python Multiprocessing</a></p>
</li>
</ul>
<iframe width=560 height=315 src=https://www.youtube.com/embed/uPeCk7Wx8HU frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<h2 id=progress-bar-for-parallel-tasks>Progress bar for parallel tasks<a hidden class=anchor aria-hidden=true href=#progress-bar-for-parallel-tasks>#</a></h2>
<p>Often one need to run some slow function in parallel in order to speed up the computation.
In user facing apps it&rsquo;s important to visualize the progress.
One can use <code>multiprocessing.Pool</code> and <code>tqdm</code> for it.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>multiprocessing</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>tqdm</span>


<span class=k>def</span> <span class=nf>slow_operation</span><span class=p>(</span><span class=n>a</span><span class=p>):</span>
    <span class=s2>&#34;&#34;&#34;
</span><span class=s2>    Slow operation, return value is not needed in main.
</span><span class=s2>    For example the function opens a file, processes it and dumps the results to a new location.
</span><span class=s2>    &#34;&#34;&#34;</span>
    <span class=n>z</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>([</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>1000</span><span class=p>])</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>50</span><span class=p>):</span>
        <span class=n>z</span> <span class=o>=</span> <span class=n>z</span> <span class=o>*</span> <span class=p>(</span><span class=n>z</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>z</span>

</code></pre></td></tr></table>
</div>
</div><p>One cannot apply tqdm to the <code>Pool.map</code> because the whole processing happens before the tqdm can iterate the result.<br>
However it&rsquo;s possible to use <code>Pool.imap</code> or <code>Pool.imap_unordered</code> if the order is not important.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python>
<span class=k>def</span> <span class=nf>parallel_with_imap_unordered</span><span class=p>():</span>
    <span class=k>with</span>  <span class=n>multiprocessing</span><span class=o>.</span><span class=n>Pool</span><span class=p>(</span><span class=mi>6</span><span class=p>)</span> <span class=k>as</span> <span class=n>pool</span><span class=p>:</span>
        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=o>.</span><span class=n>tqdm</span><span class=p>(</span><span class=n>pool</span><span class=o>.</span><span class=n>imap_unordered</span><span class=p>(</span><span class=n>slow_operation</span><span class=p>,</span> <span class=nb>range</span><span class=p>(</span><span class=mi>100</span><span class=p>)),</span> <span class=n>total</span><span class=o>=</span><span class=mi>100</span><span class=p>):</span>
            <span class=k>pass</span>
</code></pre></td></tr></table>
</div>
</div><p>It&rsquo;s nice that we don&rsquo;t need to do <code>pool.join()</code> here because <code>imap*</code> waits for all the tasks to complete.</p>
<p>Don&rsquo;t forget to set chunk size:</p>
<blockquote>
<p>For very long iterables using a large value for chunksize can make the job complete much faster than using the default value of 1.</p>
</blockquote>
<p>Alternatively we can use callbacks to update a global progress bar in a main process:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>parallel_with_callback</span><span class=p>():</span>
    <span class=n>pbar</span> <span class=o>=</span> <span class=n>tqdm</span><span class=o>.</span><span class=n>tqdm</span><span class=p>(</span><span class=n>total</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>update</span><span class=p>(</span><span class=o>*</span><span class=n>a</span><span class=p>):</span>
        <span class=n>pbar</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>

    <span class=n>pool</span> <span class=o>=</span> <span class=n>multiprocessing</span><span class=o>.</span><span class=n>Pool</span><span class=p>(</span><span class=mi>6</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>pbar</span><span class=o>.</span><span class=n>total</span><span class=p>):</span>
        <span class=n>pool</span><span class=o>.</span><span class=n>apply_async</span><span class=p>(</span><span class=n>slow_operation</span><span class=p>,</span> <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>i</span><span class=p>,),</span> <span class=n>callback</span><span class=o>=</span><span class=n>update</span><span class=p>)</span>
    <span class=n>pool</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
    <span class=n>pool</span><span class=o>.</span><span class=n>join</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><p>That method requires <code>pool.join</code> to wait for all the processes to finish.</p>
<h2 id=using-pipes-for-parallel-stateful-processes>Using Pipes for parallel stateful processes<a hidden class=anchor aria-hidden=true href=#using-pipes-for-parallel-stateful-processes>#</a></h2>
<p>Let&rsquo;s consider the following task. We have to implement a controller.
The controller defines a processing graph with 4 interconnected stages:</p>
<ul>
<li>
<p>detector</p>
</li>
<li>
<p>size_estimator (depends on detector)</p>
</li>
<li>
<p>classifier (depends on detector)</p>
</li>
<li>
<p>aggregator (depends on size_estimator and classifier)</p>
</li>
</ul>
<p>This could be a model for some computer vision pipeline and controller processes frames coming from a camera.</p>
<p>Sequential version of the controller could look like this</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=k>class</span> <span class=nc>Controller</span><span class=p>:</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>detector</span> <span class=o>=</span> <span class=n>Detector</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>size_estimator</span> <span class=o>=</span> <span class=n>Processor</span><span class=p>(</span><span class=n>fn</span><span class=o>=</span><span class=n>_compute_size</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>classifier</span> <span class=o>=</span> <span class=n>Processor</span><span class=p>(</span><span class=n>fn</span><span class=o>=</span><span class=n>_obj_to_class</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>aggregator</span> <span class=o>=</span> <span class=n>Aggregator</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>stats</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>frame</span><span class=p>):</span>
        <span class=n>objects</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>detector</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
        <span class=n>sizes</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>size_estimator</span><span class=p>(</span><span class=n>objects</span><span class=p>)</span>
        <span class=n>classes</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>classifier</span><span class=p>(</span><span class=n>objects</span><span class=p>)</span>
        <span class=n>stat</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>aggregator</span><span class=p>(</span><span class=n>sizes</span><span class=p>,</span> <span class=n>classes</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>stats</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>stat</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>finish</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>

</code></pre></td></tr></table>
</div>
</div><p>Usage of the controller:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>execute_test</span><span class=p>(</span><span class=n>controller</span><span class=p>):</span>
    <span class=n>num_frames</span> <span class=o>=</span> <span class=mi>10</span>
    <span class=n>t</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_frames</span><span class=p>):</span>
        <span class=n>frame</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>empty</span><span class=p>((</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;uint8&#39;</span><span class=p>)</span>
        <span class=n>controller</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
    <span class=n>controller</span><span class=o>.</span><span class=n>finish</span><span class=p>()</span>
    <span class=n>t</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>t</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;FPS: </span><span class=si>{</span><span class=n>num_frames</span> <span class=o>/</span> <span class=n>t</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>t</span>
</code></pre></td></tr></table>
</div>
</div><p>As I have mentioned above two stages - size estimation and classification - can be executed in parallel.
A standard solution for that could be <code>multiprocessing.Pool</code> with a function like <code>map</code> or <code>imap</code>.
That works if our processing stages are <strong>stateless and the initialization is cheap</strong>
It is not always the case.</p>
<p>If <code>classifier</code> requires a costly initialization, e.g. loading a big neural network into memory, it would be
nice to have it initialized only once. We can do it in a separate process.
If we were using a programming language other than Python, we could use threads for it.
But in python we have GIL.</p>
<p>Controller has to send data to another process and receive the results.
Communication between parallel processes is a dangerous thing.
Let&rsquo;s try to use <code>multiprocessing.Pipe</code> for that.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=k>class</span> <span class=nc>ParallelPipeController</span><span class=p>:</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>size_estimator_factory</span><span class=o>=</span><span class=k>lambda</span><span class=p>:</span> <span class=n>Processor</span><span class=p>(</span><span class=n>fn</span><span class=o>=</span><span class=n>_compute_size</span><span class=p>)):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>pipe_size_estimator</span><span class=p>,</span> <span class=n>pipe_size_worker</span> <span class=o>=</span> <span class=n>Pipe</span><span class=p>()</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>detector</span> <span class=o>=</span> <span class=n>Detector</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>size_estimator</span> <span class=o>=</span> <span class=n>Process</span><span class=p>(</span>
            <span class=n>target</span><span class=o>=</span><span class=n>pipe_worker</span><span class=p>,</span>
            <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>pipe_size_worker</span><span class=p>,</span> <span class=n>size_estimator_factory</span><span class=p>),</span>
            <span class=n>daemon</span><span class=o>=</span><span class=kc>True</span>
        <span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>classifier</span> <span class=o>=</span> <span class=n>Processor</span><span class=p>(</span><span class=n>fn</span><span class=o>=</span><span class=n>_obj_to_class</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>aggregator</span> <span class=o>=</span> <span class=n>Aggregator</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>stats</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>size_estimator</span><span class=o>.</span><span class=n>start</span><span class=p>()</span>

    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>frame</span><span class=p>):</span>
        <span class=n>objects</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>detector</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>pipe_size_estimator</span><span class=o>.</span><span class=n>send</span><span class=p>(</span><span class=n>objects</span><span class=p>)</span>
        <span class=n>classes</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>classifier</span><span class=p>(</span><span class=n>objects</span><span class=p>)</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=n>sizes</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pipe_size_estimator</span><span class=o>.</span><span class=n>recv</span><span class=p>()</span>
        <span class=k>except</span> <span class=ne>EOFError</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;Unable to get data from process. Probably exception occurred&#34;</span><span class=p>)</span> <span class=kn>from</span> <span class=nn>e</span>
        <span class=n>stat</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>aggregator</span><span class=p>(</span><span class=n>sizes</span><span class=p>,</span> <span class=n>classes</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>stats</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>stat</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>finish</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>pipe_size_estimator</span><span class=o>.</span><span class=n>send</span><span class=p>(</span><span class=kc>None</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>size_estimator</span><span class=o>.</span><span class=n>join</span><span class=p>()</span>

</code></pre></td></tr></table>
</div>
</div><p><code>pipe_worker</code> would look like this:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=k>def</span> <span class=nf>pipe_worker</span><span class=p>(</span><span class=n>pipe</span><span class=p>,</span> <span class=n>factory</span><span class=p>:</span> <span class=n>Callable</span><span class=p>):</span>
    <span class=k>try</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;worker started&#34;</span><span class=p>)</span>
        <span class=n>processor</span> <span class=o>=</span> <span class=n>factory</span><span class=p>()</span>
        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
            <span class=n>msg</span> <span class=o>=</span> <span class=n>pipe</span><span class=o>.</span><span class=n>recv</span><span class=p>()</span>
            <span class=k>if</span> <span class=n>msg</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>break</span>
            <span class=n>result</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>msg</span><span class=p>)</span>
            <span class=n>pipe</span><span class=o>.</span><span class=n>send</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;worker exited correctly&#34;</span><span class=p>)</span>
    <span class=k>except</span> <span class=ne>Exception</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;An exception occurred. We notify the main process by closing our end of the pipe.&#34;</span>
              <span class=s2>&#34;It would be nicer to send some info to the main process.&#34;</span><span class=p>)</span>
        <span class=n>pipe</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><p>Comparing those two controllers:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;sequential&#34;</span><span class=p>)</span>
<span class=n>execute_test</span><span class=p>(</span><span class=n>Controller</span><span class=p>())</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&#34;parallel&#34;</span><span class=p>)</span>
<span class=n>execute_test</span><span class=p>(</span><span class=n>ParallelPipeController</span><span class=p>())</span>
</code></pre></td></tr></table>
</div>
</div><p>Sample output:</p>
<pre><code>sequential
FPS: 1.7753397948365568
parallel
worker started
worker exited correctly
FPS: 2.820896038347416
</code></pre>
<p>Full code is <a href=https://github.com/serge-m/code-training/tree/master/python/parallel/stateful_process_workers>here</a>.</p>
<p>There are some alternative workarounds to deal with initialization in standard <code>multiprocessing</code>.
They usually require some global variables. See for example:</p>
<ul>
<li>
<p>Stack overflow <a href=https://stackoverflow.com/questions/10117073/how-to-use-initializer-to-set-up-my-multiprocess-pool>how to use initializer to set up my multiprocess pool?</a></p>
</li>
<li>
<p><a href=https://thelaziestprogrammer.com/python/multiprocessing-pool-expect-initret-proposal>Multiprocessing.Pool - Pass Data to Workers w/o Globals: A Proposal</a></p>
</li>
</ul>
<h1 id=processing-keyboardinterrupt-in-workers>Processing KeyboardInterrupt in workers<a hidden class=anchor aria-hidden=true href=#processing-keyboardinterrupt-in-workers>#</a></h1>
<p>Apparently there are some issue with KeyboardInterrupt and multiprocessing:</p>
<blockquote>
<p>when workers are idle, Python’s KeyboardInterrupt is not handled correctly
by the multiprocessing module, which results in not only a lot of stacktraces
spewed to the console, but also means the parent process will hang indefinitely.</p>
</blockquote>
<p><a href=https://noswap.com/blog/python-multiprocessing-keyboardinterrupt>Python: Using KeyboardInterrupt with a Multiprocessing Pool</a>, 2011.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://serge-m.github.io/tags/python/>python</a></li>
<li><a href=https://serge-m.github.io/tags/useful/>useful</a></li>
<li><a href=https://serge-m.github.io/tags/libraries/>libraries</a></li>
<li><a href=https://serge-m.github.io/tags/multiprocessing/>multiprocessing</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://serge-m.github.io/posts/point-cloud-processing/>
<span class=title>« Prev Page</span>
<br>
<span>Point cloud processing</span>
</a>
<a class=next href=https://serge-m.github.io/posts/self-supervised-depth-and-ego-motion/>
<span class=title>Next Page »</span>
<br>
<span>Self-supervised depth and ego motion estimation</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Python - Multiprocessing on twitter" href="https://twitter.com/intent/tweet/?text=Python%20-%20Multiprocessing&url=https%3a%2f%2fserge-m.github.io%2fposts%2fpython-multiprocessing%2f&hashtags=python%2cmultiprocessing%2cuseful%2clibraries%2cmultiprocessing"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Python - Multiprocessing on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fserge-m.github.io%2fposts%2fpython-multiprocessing%2f&title=Python%20-%20Multiprocessing&summary=Python%20-%20Multiprocessing&source=https%3a%2f%2fserge-m.github.io%2fposts%2fpython-multiprocessing%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Python - Multiprocessing on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fserge-m.github.io%2fposts%2fpython-multiprocessing%2f&title=Python%20-%20Multiprocessing"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Python - Multiprocessing on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fserge-m.github.io%2fposts%2fpython-multiprocessing%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Python - Multiprocessing on whatsapp" href="https://api.whatsapp.com/send?text=Python%20-%20Multiprocessing%20-%20https%3a%2f%2fserge-m.github.io%2fposts%2fpython-multiprocessing%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Python - Multiprocessing on telegram" href="https://telegram.me/share/url?text=Python%20-%20Multiprocessing&url=https%3a%2f%2fserge-m.github.io%2fposts%2fpython-multiprocessing%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://serge-m.github.io/>sergem's personal public notebook</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)">
<button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</button>
</a>
<script defer src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
</body>
</html>