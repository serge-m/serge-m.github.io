<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on sergem&#39;s personal public notebook</title>
    <link>https://serge-m.github.io/tags/machine-learning/</link>
    <description>Recent content in machine learning on sergem&#39;s personal public notebook</description>
    <image>
      <url>https://serge-m.github.io/papermod-cover.png</url>
      <link>https://serge-m.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 23 Aug 2020 19:00:00 +0000</lastBuildDate><atom:link href="https://serge-m.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Self-supervised depth and ego motion estimation</title>
      <link>https://serge-m.github.io/posts/self-supervised-depth-and-ego-motion/</link>
      <pubDate>Sun, 23 Aug 2020 19:00:00 +0000</pubDate>
      
      <guid>https://serge-m.github.io/posts/self-supervised-depth-and-ego-motion/</guid>
      <description>3D Packing for Self-Supervised Monocular Depth Estimation -------------------------------------------------------------- by Vitor Guizilini, `pdf at arxiv `_, 2020 Learning 1. Depth estimator :math:`f_D : I \rightarrow D` 2. Ego motion estimator: :math:`f_x : (I_t , I_S) \rightarrow x_{t \rightarrow S}` Depth Estimator ===================================== They predict an inverse depth and use a packnet architecture. Inverse depth probably has more stable results. Points far away from camera have small inverse depth that with low precision.</description>
    </item>
    
    <item>
      <title>Which pretrained backbone to choose</title>
      <link>https://serge-m.github.io/posts/which-backbone-to-choose/</link>
      <pubDate>Wed, 01 Jul 2020 19:00:00 +0000</pubDate>
      
      <guid>https://serge-m.github.io/posts/which-backbone-to-choose/</guid>
      <description>In 2020 which architecture should I use for my image classification/tracking/segmentation/&amp;hellip; task?
I was asked on an interview that and I didn&amp;rsquo;t have a prepared answer.
I made a small research and want to write down some thoughts.
Most of the architectures build upon ideas from ResNet paper Deep Residual Learning for Image Recognition, 2015
Here is some explanation of resnet family:An Overview of ResNet and its Variants by Vincent Fung, 2017.</description>
    </item>
    
    <item>
      <title>Image segmentation with unlabeled areas with fast.ai</title>
      <link>https://serge-m.github.io/posts/image-segmentation-with-unlabeled-areas-with-fast-ai/</link>
      <pubDate>Thu, 14 Nov 2019 07:28:00 +0000</pubDate>
      
      <guid>https://serge-m.github.io/posts/image-segmentation-with-unlabeled-areas-with-fast-ai/</guid>
      <description>fast.ai library has a pretty easy to use yet powerful capabilities for semantic image segmentation. By default all the classes are treated the same. The network is trained to predict all the labels.
Sometimes it&amp;rsquo;s important to provide non-complete labeling. That means for some areas the label is undefined. The performance of the network should exclude that areas in the loss and accuracy computation. That allows the network predict any other class in those areas.</description>
    </item>
    
    <item>
      <title>Rest API for TensorFlow model</title>
      <link>https://serge-m.github.io/posts/rest-api-for-tensorflow-model/</link>
      <pubDate>Sun, 21 May 2017 22:00:00 +0000</pubDate>
      
      <guid>https://serge-m.github.io/posts/rest-api-for-tensorflow-model/</guid>
      <description>TensorFlow Serving, sources - library for serving machine learning models. Written in C++ and Python. Server is in C++. Requires Bazel - Google&amp;rsquo;s build tool. Doesn&amp;rsquo;t work with python 3. Probably fast.
TensorFlow: How to freeze a model and serve it with a python API
Building a Machine Learning App with AWS Lambda (slides)
Pipeline.io - End-to-End, Continuous Spark ML + Tensorflow AI Data Pipelines, Sources
Interesting thread. They propose to use &amp;ldquo;saved_model_cli binary (in tools/), which you can feed a SavedModel, and pass input data via files.</description>
    </item>
    
    <item>
      <title>Machine learning links</title>
      <link>https://serge-m.github.io/posts/machine-learning-links/</link>
      <pubDate>Thu, 19 Jan 2017 14:10:00 +0000</pubDate>
      
      <guid>https://serge-m.github.io/posts/machine-learning-links/</guid>
      <description>Super harsh guide to machine Learning Super harsh guide to machine learning (reddit)
 First, read fucking Hastie, Tibshirani, and whoever. Chapters 1-4 and 7. If you don&amp;rsquo;t understand it, keep reading it until you do.
You can read the rest of the book if you want. You probably should, but I&amp;rsquo;ll assume you know all of it.
Take Andrew Ng&amp;rsquo;s Coursera. Do all the exercises in Matlab and python and R.</description>
    </item>
    
    <item>
      <title>Detector of flying objects in IR video</title>
      <link>https://serge-m.github.io/posts/detector-of-flying-objects-in-ir-video/</link>
      <pubDate>Sat, 12 Sep 2015 21:14:00 +0000</pubDate>
      
      <guid>https://serge-m.github.io/posts/detector-of-flying-objects-in-ir-video/</guid>
      <description>Implemented using python
https://github.com/serge-m/object_detection_ir_video</description>
    </item>
    
  </channel>
</rss>
